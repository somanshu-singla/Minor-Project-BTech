{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Minor Project - Duplicate Question Detector-Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/somanshu-singla/Minor-Project-BTech/blob/master/Minor_Project_Duplicate_Question_Detector_Keras.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "53RQl6g4lXlE",
        "colab_type": "code",
        "outputId": "8309215b-9c34-4cf4-edbf-f41ffa7c5db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YQ0Z41U2lor_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8b6ac999-b2f9-4857-a12e-93d97749b1d3"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "#path for trainig, validation and testing data\n",
        "train_data_file = '/content/drive/My Drive/project/train.csv'\n",
        "validation_data_file = '/content/drive/My Drive/project/validation.csv'\n",
        "test_data_file = '/content/drive/My Drive/project/test.csv'"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 2 µs, total: 6 µs\n",
            "Wall time: 12.4 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qxGMa0N1mG0m",
        "colab_type": "code",
        "outputId": "01ddac0d-50b3-4b8e-e8ea-c0129b2e2cdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "#using pandas to load data from csv file\n",
        "\n",
        "train_data = pd.read_csv(train_data_file)\n",
        "train_data = train_data.iloc[:, 0:6]\n",
        "\n",
        "columns_list = [\"id\", \"qid1\", \"qid2\", \"ques1\", \"ques2\", \"is_duplicate\"]\n",
        "train_data.columns = columns_list\n",
        "\n",
        "validation_data = pd.read_csv(validation_data_file)\n",
        "validation_data = validation_data.iloc[:, 0:6]\n",
        "validation_data.columns = columns_list\n",
        "\n",
        "test_data = pd.read_csv(test_data_file)\n",
        "test_data = test_data.iloc[:, 0:6]\n",
        "test_data.columns = columns_list\n",
        "\n",
        "#checking the data\n",
        "print(train_data[\"ques1\"][0:10], train_data[\"ques2\"][0:10], train_data[\"is_duplicate\"][0:10])"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    What is the step by step guide to invest in sh...\n",
            "1    What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
            "2    How can I increase the speed of my internet co...\n",
            "3    Why am I mentally very lonely? How can I solve...\n",
            "4    Which one dissolve in water quikly sugar, salt...\n",
            "5    Astrology: I am a Capricorn Sun Cap moon and c...\n",
            "6                                  Should I buy tiago?\n",
            "7                       How can I be a good geologist?\n",
            "8                      When do you use シ instead of し?\n",
            "9    Motorola (company): Can I hack my Charter Moto...\n",
            "Name: ques1, dtype: object 0    What is the step by step guide to invest in sh...\n",
            "1    What would happen if the Indian government sto...\n",
            "2    How can Internet speed be increased by hacking...\n",
            "3    Find the remainder when [math]23^{24}[/math] i...\n",
            "4              Which fish would survive in salt water?\n",
            "5    I'm a triple Capricorn (Sun, Moon and ascendan...\n",
            "6    What keeps childern active and far from phone ...\n",
            "7            What should I do to be a great geologist?\n",
            "8                When do you use \"&\" instead of \"and\"?\n",
            "9    How do I hack Motorola DCX3400 for free internet?\n",
            "Name: ques2, dtype: object 0    0\n",
            "1    0\n",
            "2    0\n",
            "3    0\n",
            "4    0\n",
            "5    1\n",
            "6    0\n",
            "7    1\n",
            "8    0\n",
            "9    0\n",
            "Name: is_duplicate, dtype: int64\n",
            "CPU times: user 83.5 ms, sys: 9.06 ms, total: 92.5 ms\n",
            "Wall time: 136 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9j6_WboLG7pZ",
        "colab_type": "code",
        "outputId": "620c04d7-511e-457f-c0a4-e5030b9ff749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "CPU times: user 48.4 ms, sys: 9.07 ms, total: 57.5 ms\n",
            "Wall time: 185 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F-SFvgFSoz18",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2c22c7f6-2576-4b1b-de3e-36fbb1cf1b8e"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "import re\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;\\'\\\"]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "\n",
        "#removing punctuations and stopwords(words like the,is)\n",
        "def text_preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(REPLACE_BY_SPACE_RE, ' ', text)\n",
        "    text = re.sub(BAD_SYMBOLS_RE, '', text)\n",
        "    text = [word for word in word_tokenize(text) if word not in string.punctuation]\n",
        "    #TODO: keep stopwords if removing it improves accuracy\n",
        "    text = [word for word in text if word not in set(stopwords.words('english'))]\n",
        "    return text"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 0 ns, sys: 31 µs, total: 31 µs\n",
            "Wall time: 40.8 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c94PyE59J8BJ",
        "colab_type": "code",
        "outputId": "dcbe7c18-e532-4419-9dc4-8c5252cb48e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#testing text_preprocesstext\n",
        "print(text_preprocess(\"This is Somanshu's notebook!\"))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['somanshu', 'notebook']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MHCYk7D_KJB3",
        "colab_type": "code",
        "outputId": "b3e04ef1-2a47-4463-9b90-83f09bce9b07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "train_QUES1_LIST = [text_preprocess(text) for text in train_data[\"ques1\"]]\n",
        "train_QUES2_LIST = [text_preprocess(text) for text in train_data[\"ques2\"]]\n",
        "\n",
        "validation_QUES1_LIST = [text_preprocess(text) for text in validation_data[\"ques1\"]]\n",
        "validation_QUES2_LIST = [text_preprocess(text)for text in validation_data[\"ques2\"]]\n",
        "\n",
        "test_QUES1_LIST = [text_preprocess(text) for text in test_data[\"ques1\"]]\n",
        "test_QUES2_LIST = [text_preprocess(text) for text in test_data[\"ques2\"]]\n",
        "\n",
        "#checking processed list\n",
        "print(train_QUES1_LIST[:3])\n",
        "print(train_QUES2_LIST[:3])"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['step', 'step', 'guide', 'invest', 'share', 'market', 'india'], ['story', 'kohinoor', 'kohinoor', 'diamond'], ['increase', 'speed', 'internet', 'connection', 'using', 'vpn']]\n",
            "[['step', 'step', 'guide', 'invest', 'share', 'market'], ['would', 'happen', 'indian', 'government', 'stole', 'kohinoor', 'kohinoor', 'diamond', 'back'], ['internet', 'speed', 'increased', 'hacking', 'dns']]\n",
            "CPU times: user 1min 35s, sys: 13 s, total: 1min 48s\n",
            "Wall time: 1min 48s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EtIVoxckVR2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "483940be-2bc6-4a16-fe91-551d12a6d195"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#dictionary (word --> embeddings) key = word, value = embeddings \n",
        "\n",
        "def load_GloVe(filename):\n",
        "    embeddings_dict = {}\n",
        "    print(\"Loading Glove Model\")\n",
        "    f = open(filename,'r')\n",
        "    for line in f:\n",
        "        word_with_embeddings = line.split()\n",
        "        word = word_with_embeddings[0]\n",
        "        embedding = np.array([float(val) for val in word_with_embeddings[1:]])\n",
        "        embeddings_dict[word] = embedding\n",
        "    print(\"Done.\",len(embeddings_dict),\"words loaded!\")\n",
        "    return embeddings_dict\n",
        "  \n",
        " \n",
        "#loading the glove file\n",
        "\n",
        "GLOVE_FILE = '/content/drive/My Drive/project/glove.6B.300d.txt'\n",
        "embeddings_dict = load_GloVe(GLOVE_FILE)\n",
        "\n",
        "#checking word embedding\n",
        "print(embeddings_dict['work'])\n",
        "  "
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Glove Model\n",
            "Done. 400000 words loaded!\n",
            "[ 7.1531e-02  2.9840e-01 -2.4760e-01 -2.0701e-02 -2.4787e-01 -1.2545e-01\n",
            " -4.6107e-01 -3.6251e-01 -1.4852e-01 -2.0094e+00 -2.6774e-02 -3.5909e-01\n",
            "  2.0173e-01  2.3331e-01  9.6492e-02 -2.3819e-01  1.6514e-01 -5.1073e-02\n",
            " -1.7086e-01  2.4222e-01 -2.1840e-02  1.8782e-01  2.8954e-01  3.6629e-02\n",
            " -1.9667e-01  3.4200e-01  9.6643e-02 -4.6427e-02 -3.9437e-02  2.2158e-01\n",
            "  7.4511e-01  7.2303e-01 -2.4423e-01  2.9758e-01 -7.5989e-01  3.2769e-01\n",
            "  1.1023e-01  6.2215e-02 -1.2149e-01 -3.0053e-01 -5.4209e-02 -1.2295e-01\n",
            " -1.3716e-01 -4.0009e-01 -3.2948e-01  3.4462e-01  1.1309e-01  4.5889e-01\n",
            " -4.1368e-01 -2.6152e-01  5.2891e-01 -7.0503e-02  2.0032e-01  3.0537e-01\n",
            " -1.6813e-01  4.3551e-01 -1.6354e-01  6.1143e-02 -1.9790e-01  2.1224e-01\n",
            "  1.9729e-01  1.1441e-01  3.0642e-01  2.1874e-02 -1.3517e-01 -2.6030e-01\n",
            "  3.8787e-01  1.3788e-01  2.8582e-01 -2.1430e-01  5.2672e-02 -3.2403e-01\n",
            "  1.5975e-01  3.2645e-01 -7.6972e-02  7.2519e-02 -2.0695e-01  4.7658e-01\n",
            "  1.1149e-01 -2.1596e-01 -4.0987e-01 -1.4983e-01 -4.8563e-02 -1.0902e-01\n",
            " -3.4951e-03  1.9598e-01  2.0803e-01  5.6150e-02 -9.4225e-02 -7.7260e-02\n",
            " -6.5196e-02  8.0829e-02  1.2869e-01 -7.4671e-02 -9.9291e-02 -8.5286e-01\n",
            " -3.3267e-01 -7.5351e-01  5.5281e-02 -4.2798e-01  6.5838e-02  5.6239e-02\n",
            " -4.9553e-01 -2.5178e-01 -1.1147e-01 -1.9986e-01  2.3411e-01  3.6973e-01\n",
            "  8.8861e-02 -3.7278e-01 -8.8642e-02 -2.6808e-01 -2.7127e-01 -3.1972e-01\n",
            " -5.1719e-01  1.5972e-01 -7.9731e-02 -1.5211e-01 -1.1859e-01 -1.3506e-01\n",
            " -7.1106e-02 -2.5752e-02 -2.6866e-02 -3.8582e-02  2.8034e-01 -1.7165e-01\n",
            "  1.6503e-01  2.0218e-01  3.7191e-02  6.4428e-02  1.9170e-01  1.6190e-01\n",
            "  4.6020e-01 -2.9599e-01 -7.4266e-01 -3.1196e-01 -5.4693e-01 -1.9597e-01\n",
            "  1.6324e-01 -1.1511e-01  1.2945e-01  2.0865e-01  1.4107e-01 -9.3395e-02\n",
            "  7.0872e-02 -1.5246e-01  1.2510e-01  3.7021e-01  2.6408e-01 -1.3732e-01\n",
            "  1.6534e-01 -9.9602e-02  3.8121e-02 -1.5855e-01  2.5918e-01 -2.5439e-02\n",
            " -1.7617e-01  6.3166e-02  5.9122e-01 -2.8494e-01 -2.4036e-01 -4.0399e-01\n",
            "  3.0865e-01 -4.8065e-02 -1.9282e-01  6.6170e-02 -6.7667e-02  8.7555e-02\n",
            "  3.1809e-01  4.2883e-01  2.7488e-01  9.1586e-03 -1.0891e+00 -9.3335e-02\n",
            "  6.9775e-02  2.6234e-01 -5.1971e-01 -3.2751e-01 -4.7615e-01  5.4052e-03\n",
            "  7.3499e-02  1.4224e-01 -5.9111e-02 -1.4999e-02 -1.5395e-01 -3.2571e-03\n",
            " -3.5682e-01 -4.0630e-03 -6.4693e-02 -3.5851e-01 -2.5424e-01  3.8660e-01\n",
            "  3.1949e-01  1.6097e-01 -1.6455e-01 -3.1871e-01 -5.5213e-01  5.2687e-01\n",
            "  1.1355e-01 -5.4443e-01  6.6721e-01  1.2822e-01  2.5732e-01  3.1301e-01\n",
            "  4.6955e-01  3.3419e-01 -1.2548e-01  6.0845e-02  2.3884e-02 -4.8377e-01\n",
            "  2.7514e-01 -1.3563e-02 -6.6597e-04  9.3824e-02  2.0813e-01  3.6350e-01\n",
            " -5.1869e-01  5.1876e-01  1.9794e-01  1.0869e-01  2.0908e-01 -1.1269e-01\n",
            " -5.6824e-01  2.8625e-01  6.8070e-02 -3.6988e-01  1.7055e-01 -5.8472e-02\n",
            " -1.7684e-01 -2.0339e-01  7.9617e-02 -9.7225e-02  6.3183e-02 -1.8705e-01\n",
            " -3.1983e-03  1.9663e-01  1.3329e-01  1.1843e-01 -3.3487e-01 -9.8260e-02\n",
            "  1.0315e-01  2.7482e-02  2.0772e-01  6.3050e-02 -8.4154e-01 -7.3824e-02\n",
            " -1.9884e-01 -5.3505e-02 -8.4831e-02  1.3781e-01  2.4670e-02 -1.1261e-01\n",
            "  1.4948e-01  3.2934e-01  9.4771e-01 -1.6012e-01 -8.6568e-03  1.7529e-01\n",
            "  2.0499e-01  4.3256e-01  2.4081e-01 -2.4000e-03  3.4630e-01  5.6605e-02\n",
            "  1.6888e-01  2.7937e-01 -3.3116e-01  1.3859e-02 -6.2748e-02 -2.8689e-01\n",
            "  1.9460e-02  1.8461e-01  1.7958e-01  1.0852e-01  2.1653e-02  7.6598e-02\n",
            " -2.2000e+00 -3.3291e-01  5.5248e-01  1.3120e-01  3.3885e-02 -1.5475e-01\n",
            "  3.0374e-01  2.7741e-01  2.0516e-01  2.6855e-01  9.2416e-02  5.7706e-01\n",
            " -1.7464e-01 -2.8769e-01 -3.5143e-01 -4.4734e-01  9.5513e-02 -1.6860e-01\n",
            "  3.0341e-01  1.2320e-01  3.0802e-01 -5.7444e-02 -4.0008e-02 -5.1519e-02]\n",
            "CPU times: user 41.6 s, sys: 2.3 s, total: 43.9 s\n",
            "Wall time: 44.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "23RuBra27l-L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#hyperparameters values\n",
        "num_epochs      = 64\n",
        "batch_size      = 64\n",
        "wordvectdim     = 300\n",
        "sentencepad     = 20\n",
        "num_classes     = 2\n",
        "cnnfiltersize   = (1,300)\n",
        "poolsize        = (sentencepad,1)\n",
        "num_filters     = 1800\n",
        "cnninitial      = 'he_uniform'\n",
        "relu            = 'relu'\n",
        "dense1size      = 1800\n",
        "dense2size      = 600\n",
        "denseinitial    = 'he_uniform'\n",
        "denseactivate   = 'tanh'\n",
        "outputactivate  = 'softmax'\n",
        "optimizer       = 'SGD'\n",
        "num_channel     = 1\n",
        "lossfunction    = 'categorical_crossentropy'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BXSO7eDwYR7w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7935a713-fa5b-4163-ac16-7ddda7845789"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "foo1=0\n",
        "foo2=0\n",
        "#prepares input for CNN model\n",
        "def prepare_input(sentence_list_1,sentence_list_2):\n",
        "    input_list_1,input_list_2 = np.zeros((len(sentence_list_1),num_channel,sentencepad,wordvectdim)) , np.zeros((len(sentence_list_2),num_channel,sentencepad,wordvectdim))\n",
        "    i = 0\n",
        "    for i in range(len(sentence_list_1)):\n",
        "      sentence_matrix_1 = np.zeros((num_channel,sentencepad,wordvectdim))\n",
        "      sentence_matrix_2 = np.zeros((num_channel,sentencepad,wordvectdim))\n",
        "      foo = 0\n",
        "      j = 1 \n",
        "      for word in sentence_list_1[i]:\n",
        "        if j > sentencepad:\n",
        "          break\n",
        "        if word in embeddings_dict:\n",
        "          sentence_matrix_1[0][j-1] = embeddings_dict[word]\n",
        "        else:\n",
        "          sentence_matrix_1[0][j-1] = np.zeros(wordvectdim)\n",
        "        j = j+1\n",
        "       \n",
        "\n",
        "      j = 1\n",
        "      foo=0\n",
        "      for word in sentence_list_2[i]:\n",
        "        if j > sentencepad:\n",
        "          break\n",
        "        if word in embeddings_dict:\n",
        "          sentence_matrix_2[0][j-1] = embeddings_dict[word]\n",
        "        else:\n",
        "          sentence_matrix_2[0][j-1] = np.zeros(wordvectdim)\n",
        "        j = j+1\n",
        "          \n",
        "      input_list_1[i] = (sentence_matrix_1)\n",
        "      input_list_2[i] = (sentence_matrix_2)\n",
        "    \n",
        "    return input_list_1,input_list_2          \n",
        "    "
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 13 µs, sys: 0 ns, total: 13 µs\n",
            "Wall time: 21 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T3keyWNAmUOE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "cf63cf79-1c24-4747-9966-dda66c75606c"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "#testing the prepared input\n",
        "input_train_list_1,input_train_list_2 = prepare_input(train_QUES1_LIST,train_QUES2_LIST)\n",
        "\n",
        "\n",
        "input_validation_list_1,input_validation_list_2 = prepare_input(validation_QUES1_LIST,validation_QUES2_LIST)\n",
        "\n",
        "input_test_list_1,input_test_list_2 = prepare_input(test_QUES1_LIST,test_QUES2_LIST)\n",
        "\n",
        "\n",
        "print(\"Train List Dimension : \",input_train_list_1.shape)\n",
        "print(\"Validate List Dimension : \",input_validation_list_1.shape)\n",
        "print(\"Test List Dimension : \",input_test_list_1.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train List Dimension :  (20000, 1, 20, 300)\n",
            "Validate List Dimension :  (2000, 1, 20, 300)\n",
            "Test List Dimension :  (2000, 1, 20, 300)\n",
            "CPU times: user 1.39 s, sys: 1.01 s, total: 2.4 s\n",
            "Wall time: 2.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XM_bcZXB5urr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import subtract\n",
        "from keras.layers import multiply\n",
        "from keras.layers import maximum\n",
        "from keras.layers import concatenate\n",
        "\n",
        "\n",
        "def create_model():\n",
        "  \n",
        "    input_layer_1 = Input(shape=(num_channel,sentencepad,wordvectdim))\n",
        "    input_layer_2 = Input(shape=(num_channel,sentencepad,wordvectdim))\n",
        "    \n",
        "    convolution_layer = Conv2D(filters=num_filters,kernel_size=cnnfiltersize,padding=\"valid\",data_format=\"channels_first\",activation=relu,kernel_initializer=cnninitial)\n",
        "    \n",
        "    max_pool_layer = MaxPooling2D(pool_size=poolsize,padding=\"valid\",data_format=\"channels_first\")\n",
        "    \n",
        "    flatten_layer = Flatten(data_format = \"channels_first\")\n",
        "    \n",
        "    conv_layer_output_1 = convolution_layer(input_layer_1)\n",
        "    conv_layer_output_2 = convolution_layer(input_layer_2)\n",
        "    \n",
        "    pool_layer_output_1 = max_pool_layer(conv_layer_output_1)\n",
        "    pool_layer_output_2 = max_pool_layer(conv_layer_output_2)\n",
        "    \n",
        "    flatten_layer_output_1 = flatten_layer(pool_layer_output_1)\n",
        "    flatten_layer_output_2 = flatten_layer(pool_layer_output_2)\n",
        "    \n",
        "    sub_1_1 = subtract(inputs=[flatten_layer_output_1,flatten_layer_output_2])\n",
        "    sub_1_2 = subtract(inputs=[flatten_layer_output_2,flatten_layer_output_1])\n",
        "    \n",
        "    abs_layer = maximum(inputs = [sub_1_1,sub_1_2])\n",
        "    mul_layer = multiply(inputs = [flatten_layer_output_1,flatten_layer_output_2])\n",
        "    \n",
        "    concatenate_layer = concatenate(inputs=[abs_layer,mul_layer])\n",
        "    \n",
        "    dense_layer_1 = Dense(units=dense1size,activation=denseactivate,kernel_initializer=denseinitial)(concatenate_layer)\n",
        "    \n",
        "    dense_layer_2 = Dense(units=dense2size,activation=denseactivate,kernel_initializer=denseinitial)(dense_layer_1)\n",
        "    \n",
        "    output_layer = Dense(units=num_classes,activation=outputactivate)(dense_layer_2)\n",
        "    \n",
        "    model = Model(inputs=[input_layer_1,input_layer_2],outputs=output_layer)\n",
        "    \n",
        "    print(model.summary())\n",
        "    \n",
        "    return model\n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QJOxZsw2NbCl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "outputId": "2e3cb245-3696-4e0b-ebc5-2e1db9e6cad6"
      },
      "cell_type": "code",
      "source": [
        "model = create_model()"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_21 (InputLayer)           (None, 1, 20, 300)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_22 (InputLayer)           (None, 1, 20, 300)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 1800, 20, 1)  541800      input_21[0][0]                   \n",
            "                                                                 input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 1800, 1, 1)   0           conv2d_11[0][0]                  \n",
            "                                                                 conv2d_11[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_11 (Flatten)            (None, 1800)         0           max_pooling2d_11[0][0]           \n",
            "                                                                 max_pooling2d_11[1][0]           \n",
            "__________________________________________________________________________________________________\n",
            "subtract_19 (Subtract)          (None, 1800)         0           flatten_11[0][0]                 \n",
            "                                                                 flatten_11[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "subtract_20 (Subtract)          (None, 1800)         0           flatten_11[1][0]                 \n",
            "                                                                 flatten_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "maximum_10 (Maximum)            (None, 1800)         0           subtract_19[0][0]                \n",
            "                                                                 subtract_20[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "multiply_10 (Multiply)          (None, 1800)         0           flatten_11[0][0]                 \n",
            "                                                                 flatten_11[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 3600)         0           maximum_10[0][0]                 \n",
            "                                                                 multiply_10[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 1800)         6481800     concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_23 (Dense)                (None, 600)          1080600     dense_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 2)            1202        dense_23[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 8,105,402\n",
            "Trainable params: 8,105,402\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZO1q32CuN0gK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.losses import categorical_crossentropy,sparse_categorical_crossentropy\n",
        "from keras.optimizers import SGD\n",
        "optimizer = SGD(lr=0.01)\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = optimizer,metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ePaHCynfRHAG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "e974c966-7660-41c0-c1d1-1412e3e6c03b"
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "model.fit([input_train_list_1, input_train_list_2], to_categorical(train_data['is_duplicate']), batch_size = batch_size , epochs= 6 ,verbose=1,validation_data = ([input_validation_list_1,input_validation_list_2],to_categorical(validation_data['is_duplicate'])))"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 2000 samples\n",
            "Epoch 1/6\n",
            "20000/20000 [==============================] - 15s 759us/step - loss: 0.5661 - acc: 0.7023 - val_loss: 0.5028 - val_acc: 0.7600\n",
            "Epoch 2/6\n",
            "20000/20000 [==============================] - 14s 710us/step - loss: 0.4885 - acc: 0.7500 - val_loss: 0.4802 - val_acc: 0.7585\n",
            "Epoch 3/6\n",
            "20000/20000 [==============================] - 14s 721us/step - loss: 0.4616 - acc: 0.7694 - val_loss: 0.5070 - val_acc: 0.7275\n",
            "Epoch 4/6\n",
            "20000/20000 [==============================] - 15s 726us/step - loss: 0.4421 - acc: 0.7826 - val_loss: 0.6132 - val_acc: 0.6910\n",
            "Epoch 5/6\n",
            "20000/20000 [==============================] - 15s 729us/step - loss: 0.4268 - acc: 0.7923 - val_loss: 0.5132 - val_acc: 0.7325\n",
            "Epoch 6/6\n",
            "20000/20000 [==============================] - 14s 724us/step - loss: 0.4142 - acc: 0.7996 - val_loss: 0.4781 - val_acc: 0.7520\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8029de52e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "metadata": {
        "id": "FZnR0biMR0G8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e0c47c1-ac7c-4ab1-f5ef-f391007e8b6d"
      },
      "cell_type": "code",
      "source": [
        " #predicting socres\n",
        "scores = model.predict([input_test_list_1,input_test_list_2],batch_size=batch_size,verbose = 1)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 1s 370us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tva35kFBYQBX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4e9145ce-1129-4c4e-a366-44983f37efdc"
      },
      "cell_type": "code",
      "source": [
        "print(scores)\n",
        "ss=[]\n",
        "for i in range(len(scores)):\n",
        "    ss.append(np.argmax(scores[i]))\n",
        "scores1=ss\n"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.9406146  0.05938545]\n",
            " [0.27021953 0.72978044]\n",
            " [0.9069184  0.09308164]\n",
            " ...\n",
            " [0.99686867 0.00313129]\n",
            " [0.29620543 0.7037946 ]\n",
            " [0.5072218  0.49277815]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WwEVPZPfOmYw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "ebc02af7-4a85-4ce8-bb19-cf4464416084"
      },
      "cell_type": "code",
      "source": [
        "print(scores1)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ktFTZ1d0XmEX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "222893e2-dd3e-45e7-d52b-9e2859eaec54"
      },
      "cell_type": "code",
      "source": [
        "#number of wrong predictions\n",
        "wrong = 0\n",
        "for i in range(len(scores1)):\n",
        "    if scores1[i] != test_data['is_duplicate'][i]:\n",
        "      wrong = wrong + 1\n",
        "      \n",
        "print(\"Accuracy : \",1-wrong/len(scores1))"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :  0.7575000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kHvIplAfYMmA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "a58229a0-56b2-40dc-f00a-bec26b430b90"
      },
      "cell_type": "code",
      "source": [
        "!-smi"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: -c: option requires an argument\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Prb3yaMN44ld",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}